# T01舆情分析优化方案

## 概述
本文档描述T01舆情分析模块的短期优化、中长期优化及系统集成方案。

## 一、短期优化 (已实现)

### 1.1 查询优化
**问题**: 原始查询词过于简单，返回大量英文新闻，相关性低
**解决方案**:
- 添加中文限定词: "中国"、"A股"、"沪市"、"深市"
- 市场标识自动识别: 根据股票代码(.SH/.SZ)添加相应市场标识
- 查询词扩展: 4个优化查询词组合
  ```
  原始: "美邦股份 605033.SH 涨停"
  优化: "美邦股份 605033.SH 沪市 中国 A股 涨停板 涨停"
  ```

### 1.2 参数优化
- **回溯天数**: 从3天减少到1天，提高新闻时效性
- **返回数量**: 保持5条/查询，平衡相关性与覆盖面
- **超时设置**: 30秒超时，避免长时间阻塞

### 1.3 情感分析优化
- **中英文关键词扩展**: 
  - 中文关键词: 利好、增长、超预期、突破、创新高
  - 英文关键词: positive、growth、beat、outperform、buy
- **评分算法改进**:
  - 基础分: 有新闻关注度 +2分
  - 正面新闻加分: 每条正面新闻 +0.5分 (上限3分)
  - 情感得分映射: (-1到1) → (0到3分)
  - 新闻数量加分: 每篇新闻 +0.1分 (上限2分)
  - 总分范围: 0-10分

### 1.4 系统集成
- **配置权重**: `config.yaml` 添加 `sentiment: 10`
- **评分模块**: `limit_up_strategy_new.py` 集成 `_score_sentiment()` 方法
- **总分计算**: 作为第7个评分维度加入总分计算
- **数据存储**: 在结果字典中添加 `sentiment_score` 字段

## 二、中长期优化方案

### 2.1 新闻源过滤与优先级
**目标**: 提高中文新闻比例和相关性

**方案**:
1. **中文媒体白名单**
   - 优先源: 新浪财经、东方财富、财联社、证券时报
   - 通用源: 网易财经、腾讯财经、搜狐财经
   - 专业源: 华尔街见闻、雪球、同花顺

2. **语言检测与过滤**
   - 使用langdetect库检测新闻语言
   - 优先处理中文新闻，英文新闻降权或过滤
   - 混合语言新闻提取中文部分分析

3. **域名优先级评分**
   ```python
   domain_priority = {
       'finance.sina.com.cn': 1.0,
       'eastmoney.com': 1.0,
       'cls.cn': 1.0,
       'stcn.com': 1.0,
       'xueqiu.com': 0.8,
       'wallstreetcn.com': 0.8
   }
   ```

### 2.2 NLP模型升级
**目标**: 提高情感分析准确性

**方案**:
1. **预训练模型集成**
   - 中文情感分析: SnowNLP, BERT-情感分析
   - 金融领域微调: 使用金融新闻语料微调模型
   - 上下文理解: 识别"涨停"、"利好"等金融语境

2. **多维度情感分析**
   - 情感强度: 强烈正面、温和正面、中性、温和负面、强烈负面
   - 确定性: 确定语气 vs 推测语气
   - 主题相关性: 新闻与股票的实际关联度

3. **情感传播分析**
   - 识别新闻中的因果关系
   - 分析多个新闻的情感一致性
   - 检测情感趋势变化

### 2.3 性能优化
**目标**: 减少API调用，提高运行效率

**方案**:
1. **缓存机制**
   - 新闻结果缓存: 按(股票代码+日期)缓存24小时
   - 情感分析缓存: 按新闻内容MD5缓存结果
   - 分布式缓存: Redis/Memcached支持多进程

2. **异步并行处理**
   - 异步HTTP请求: 使用aiohttp并发请求
   - 并行新闻搜索: 同时发起多个查询
   - 批处理: 批量股票同时分析

3. **智能过滤阈值**
   - 基础分阈值: 仅对基础分>60的股票进行深度舆情分析
   - 时间阈值: 交易时间优先，非交易时间完整分析
   - 数量阈值: 每只股票最多分析前20条相关新闻

### 2.4 动态权重调整
**目标**: 根据市场状态调整舆情权重

**方案**:
1. **市场状态识别**
   - 牛市特征: 高成交量，普涨行情
   - 熊市特征: 低成交量，普跌行情
   - 震荡市特征: 板块轮动，个股分化

2. **权重自适应**
   ```python
   # 舆情权重动态调整
   if market_state == 'bull':
       sentiment_weight = base_weight * 1.2  # 牛市增加权重
   elif market_state == 'bear':
       sentiment_weight = base_weight * 0.8  # 熊市降低权重
   else:
       sentiment_weight = base_weight
   ```

3. **行业特性适配**
   - 高关注度行业: 科技、医药、新能源 → 舆情权重+20%
   - 低关注度行业: 传统制造、公用事业 → 舆情权重-20%
   - 政策敏感行业: 房地产、金融 → 特殊处理

### 2.5 多数据源融合
**目标**: 构建全面的舆情监测体系

**方案**:
1. **社交舆情监测**
   - 微博话题热度
   - 雪球讨论热度
   - 投资者互动平台情绪

2. **研报数据整合**
   - 券商研究报告情感分析
   - 目标价变动追踪
   - 评级变化监测

3. **公告自动解读**
   - 公司公告摘要生成
   - 重大事项识别
   - 业绩预告情感分析

4. **宏观舆情关联**
   - 行业政策影响分析
   - 宏观经济数据解读
   - 国际市场情绪传导

## 三、实施路线图

### 阶段一: 基础优化 (已完成)
- 查询优化与参数调整
- 基本情感分析集成
- 权重配置与测试验证

### 阶段二: 性能提升 (计划1-2周)
- 新闻源过滤实现
- 缓存机制集成
- 异步处理改造

### 阶段三: 模型升级 (计划3-4周)
- NLP模型集成与测试
- 多维度情感分析
- 动态权重调整

### 阶段四: 全面监测 (计划5-6周)
- 多数据源融合
- 实时舆情监控
- 自适应学习系统

## 四、风险评估与缓解

### 4.1 API限制风险
- **风险**: Tavily API调用频率限制
- **缓解**: 实现请求队列与限流，备选数据源准备

### 4.2 性能风险
- **风险**: 舆情分析大幅延长评分时间
- **缓解**: 缓存机制、异步处理、智能过滤

### 4.3 准确性风险
- **风险**: 情感分析误判导致错误评分
- **缓解**: 多模型投票、人工样本验证、持续优化

### 4.4 数据质量风险
- **风险**: 新闻源质量不稳定
- **缓解**: 多源验证、可信度评分、异常检测

## 五、监控指标

### 5.1 性能指标
- 舆情分析平均耗时
- API调用成功率
- 缓存命中率

### 5.2 质量指标
- 中文新闻比例
- 情感分析准确率
- 新闻相关性评分

### 5.3 业务指标
- 舆情评分与股价相关性
- 舆情权重贡献度
- 策略回测表现改进

## 六、集成要求

### 6.1 环境依赖
- Python 3.8+
- Tavily API密钥
- 可选: Redis (缓存)
- 可选: GPU (NLP模型加速)

### 6.2 配置项
```yaml
sentiment:
  enabled: true
  weight: 10
  cache_enabled: true
  cache_ttl: 86400
  max_concurrent: 5
  timeout: 30
  sources:
    - sina
    - eastmoney
    - cls
  language_filter: zh
```

### 6.3 日志监控
- 舆情分析成功/失败记录
- API调用统计
- 情感分析结果分布

## 七、总结

舆情分析作为T01策略的重要补充，通过短期优化已实现基本功能集成，中长期优化将逐步提升分析准确性、性能和实用性。建议采用渐进式实施，每个阶段验证效果后再推进下一阶段。

---
**版本**: 1.0  
**创建日期**: 2026-02-24  
**最后更新**: 2026-02-24  
**负责人**: 小虾米 AI助手